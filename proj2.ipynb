{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "y-J0ihEX2nJC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3c4b78a-2c11-40a3-8fd4-e1803e390c74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt') # punkt tokenizer for sentence tokenization\n",
        "nltk.download('stopwords') # list of stop words, such as 'a', 'an', 'the', 'in', etc, which would be dropped\n",
        "from collections import Counter # Imports the Counter class from the collections module, used for counting the frequency of words in a text.\n",
        "from nltk.corpus import stopwords # Imports the stop words list from the NLTK corpus\n",
        "# corpus is a large collection of text or speech data used for statistical analysis\n",
        "\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize # Imports the sentence tokenizer and word tokenizer from the NLTK tokenizer module. \n",
        "# Sentence tokenizer is for splitting text into sentences\n",
        "# word tokenizer is for splitting sentences into words\n",
        "\n",
        "# this function would take 2 inputs, one being the text, and the other being the summary which would contain the number of lines\n",
        "def generate_summary_frequency(text, n):\n",
        "  # Tokenize the text into individual sentences\n",
        "  sentences = sent_tokenize(text)\n",
        "\n",
        "  # Tokenize each sentence into individual words and remove stopwords\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  # the following line would tokenize each sentence from sentences into individual words using the word_tokenize function of nltk.tokenize module\n",
        "  # Then removes any stop words and non-alphanumeric characters from the resulting list of words and converts them all to lowercase\n",
        "  words = [word.lower() for word in word_tokenize(text) if word.lower() not in stop_words and word.isalnum()]\n",
        "\n",
        "  # Compute the frequency of each word\n",
        "  word_freq = Counter(words)\n",
        "\n",
        "  # Compute the score for each sentence based on the frequency of its words\n",
        "  # After this block of code is executed, sentence_scores will contain the scores of each sentence in the given text, \n",
        "  # where each score is a sum of the frequency counts of its constituent words\n",
        "\n",
        "  # empty dictionary to store the scores for each sentence\n",
        "  sentence_scores = {}\n",
        "\n",
        "  for sentence in sentences:\n",
        "    sentence_words = [word.lower() for word in word_tokenize(sentence) if word.lower() not in stop_words and word.isalnum()]\n",
        "    sentence_score = sum([word_freq[word] for word in sentence_words])\n",
        "    if len(sentence_words) < 20:\n",
        "      sentence_scores[sentence] = sentence_score\n",
        "\n",
        "  # checks if the length of the sentence_words list is less than 20 (parameter can be adjusted based on the desired length of summary sentences)\n",
        "  # If condition -> true, score of the current sentence is added to the sentence_scores dictionary with the sentence itself as the key\n",
        "  # This is to filter out very short sentences that may not provide meaningful information for summary generation\n",
        "\n",
        "  # Select the top n sentences with the highest scores\n",
        "  summary_sentences = sorted(sentence_scores, key=sentence_scores.get, reverse=True)[:n]\n",
        "  summary = ' '.join(summary_sentences)\n",
        "\n",
        "  return summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing TfidfVectorizer class to convert a collection of raw documents to a matrix of TF-IDF features.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# importing cosine_similarity function to compute the cosine similarity between two vectors.\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# importing nlargest to return the n largest elements from an iterable in descending order.\n",
        "from heapq import nlargest\n",
        "\n",
        "def generate_summary_tfidf(text, n):\n",
        "  # Tokenize the text into individual sentences\n",
        "  sentences = sent_tokenize(text)\n",
        "\n",
        "  # Create the TF-IDF matrix\n",
        "  vectorizer = TfidfVectorizer(stop_words='english')\n",
        "  tfidf_matrix = vectorizer.fit_transform(sentences)\n",
        "\n",
        "  # Compute the cosine similarity between each sentence and the document\n",
        "  sentence_scores = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])[0]\n",
        "\n",
        "  # Select the top n sentences with the highest scores\n",
        "  summary_sentences = nlargest(n, range(len(sentence_scores)), key=sentence_scores.__getitem__)\n",
        "\n",
        "  summary_tfidf = ' '.join([sentences[i] for i in sorted(summary_sentences)])\n",
        "\n",
        "  return summary_tfidf"
      ],
      "metadata": {
        "id": "9U0RlfxF_0K1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''\n",
        "Weather is the day-to-day or hour-to-hour change in the atmosphere. \n",
        "Weather includes wind, lightning, storms, hurricanes, tornadoes (also known as twisters), rain, hail, snow, and lots more. \n",
        "Energy from the Sun affects the weather too. \n",
        "Climate tells us what kinds of weather usually happen in an area at different times of the year. \n",
        "Changes in weather can affect our mood and life. We wear different clothes and do different things in different weather conditions. \n",
        "We choose different foods in different seasons.\n",
        "Weather stations around the world measure different parts of weather. \n",
        "Ways to measure weather are wind speed, wind direction, temperature and humidity. \n",
        "People try to use these measurements to make weather forecasts for the future. \n",
        "These people are scientists that are called meteorologists. \n",
        "They use computers to build large mathematical models to follow weather trends.'''\n",
        "\n",
        "summary_1 = generate_summary_frequency(text, 5)\n",
        "summary_sentences_1 = summary_1.split('. ')\n",
        "formatted_summary_1 = '.\\n'.join(summary_sentences_1)\n",
        "\n",
        "print(formatted_summary_1)\n",
        "print()\n",
        "\n",
        "summary_2 = generate_summary_tfidf(text, 5)\n",
        "summary_sentences_2 = summary_2.split('. ')\n",
        "formatted_summary_2 = '.\\n'.join(summary_sentences_2)\n",
        "\n",
        "print(formatted_summary_2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37S71scM_5cX",
        "outputId": "8cfc631d-4efb-43fa-a6f5-fac8651be136"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We wear different clothes and do different things in different weather conditions.\n",
            "Weather stations around the world measure different parts of weather.\n",
            "Climate tells us what kinds of weather usually happen in an area at different times of the year.\n",
            "Weather includes wind, lightning, storms, hurricanes, tornadoes (also known as twisters), rain, hail, snow, and lots more.\n",
            "Ways to measure weather are wind speed, wind direction, temperature and humidity.\n",
            "\n",
            "Energy from the Sun affects the weather too.\n",
            "Changes in weather can affect our mood and life.\n",
            "We wear different clothes and do different things in different weather conditions.\n",
            "Weather stations around the world measure different parts of weather.\n",
            "People try to use these measurements to make weather forecasts for the future.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rouge\n",
        "from rouge import Rouge\n",
        "# a defined function called evaluate_rouge taking two arguments, \n",
        "# one being reference text and the other summary text, \n",
        "# and uses the ROUGE metric to evaluate the quality of the summary text compared to the reference text.\n",
        "# The function uses the rouge library to compute the ROUGE scores and returns the F1 score of the ROUGE-1 metric.\n",
        "def evaluate_rouge(reference_text, summary_text):\n",
        "  rouge = Rouge()\n",
        "  scores = rouge.get_scores(reference_text, summary_text)\n",
        "  return scores[0]['rouge-1']['f']\n",
        "\n",
        "\n",
        "# the following is a human generated summary\n",
        "reference_summary = '''\n",
        "Weather is a gradual slow change through days and hours in the atmosphere and can vary from wind to snow. \n",
        "Climate tells a lot about the weather in an area.\n",
        "The livelihood of people changes according to the change in weather.\n",
        "Weather stations measure different parts of weather.\n",
        "People who use measurements to make weather forecasts for the future are called meteorologists, and are scientists.'''\n",
        "\n",
        "# Generate summary using frequency-based/TF-IDF approach\n",
        "summary_1 = generate_summary_frequency(text, 5)\n",
        "\n",
        "summary_2 = generate_summary_tfidf(text, 5)\n",
        "\n",
        "# Evaluate the summary using ROUGE\n",
        "rouge_score_1 = evaluate_rouge(reference_summary, summary_1)\n",
        "rouge_score_2 = evaluate_rouge(reference_summary, summary_2)\n",
        "\n",
        "\n",
        "print(f\"ROUGE score from frequency method: {rouge_score_1}\")\n",
        "print(f\"ROUGE score from frequency method: {rouge_score_2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Klk42bo4__Jb",
        "outputId": "07e29925-d342-4fa3-8ec6-b72e498af3cc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE score from frequency method: 0.3366336583785904\n",
            "ROUGE score from frequency method: 0.45977010999603646\n"
          ]
        }
      ]
    }
  ]
}